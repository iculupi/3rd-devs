![](https://cloud.overment.com/S03E05-1732262396.png)

The hybrid search we talked about in lesson S03E03 achieves high effectiveness in accurately accessing information directly contained in a dataset. However, in everyday situations, we're often interested in obtaining answers to questions requiring more than just "finding a needle in a haystack."

Imagine a situation where we have an AI agent capable of storing information about knowledge resources. Its capabilities will allow us to easily recall the name or link to material we saw a few months earlier, even if we don't provide the exact name, but only a general description.

For the sake of order and easier searching, resources are divided into categories: **applications, devices, books, courses, movies, videos, images, communities, music, articles, YouTube channels, documents, and notes.**

![](https://cloud.overment.com/2024-10-13/aidevs3_resources-4031b42c-b.png)

If we ask about a "graph database," the agent will select the category "apps" and easily associate it with a note about Neo4J. Semantic search combined with a category filter narrowing the search area will suffice.

![](https://cloud.overment.com/2024-10-13/aidevs3_simple_search-9be4642e-6.png)

The search process becomes significantly more complicated when querying about a "**list of tools mentioned in the materials on Neo4J**."

Here, neither keyword matching nor meaning matching is sufficient. Even using filters may prove inadequate, as the search process gets complicated, despite the fact that we're talking about quite a simple query.

This is where graph databases like Neo4J come into play, allowing the result for the above query to appear as follows:

![](https://cloud.overment.com/2024-10-13/aidevs3_graph-987e68a7-e.png)

This is a graph whose structure consists of so-called "nodes," which can be compared to documents or records, and "edges" describing the relationships between them. Both "nodes" and "edges" form the two basic elements of the graph structure.

For our inquiry, we received a central document on Neo4J. It was linked with three documents (2x article, 1x video), which also have their links to documents mentioned in their content.

Such a result was possible with the help of a single, simple query written in [Cypher](https://en.wikipedia.org/wiki/Cypher_(query_language)) (a query language similar to SQL).

![](https://cloud.overment.com/2024-10-13/aidevs3_cypher-2450f2e0-8.png)

The conclusions are as follows:

- Full-text and semantic search works well when we need to access the information contained in a dataset precisely. However, capturing a broader perspective or finding connections is very challenging.
- Graph databases allow building connections between documents and navigating the graph structure to search for information scattered throughout the dataset.

This leads to a valid question about when a graph database might prove useful and whether it will indeed always address all our problems.

## Introduction to Neo4J

When choosing a graph database, we have at least a few options at our disposal, but among all, Neo4J stands out the most. It’s a very mature solution that has found its place in the world of generative AI.

In our case, we'll use the OpenSource version, [whose installation varies by operating system](https://neo4j.com/docs/operations-manual/current/installation/) (for macOS, simply use `brew install neo4j` and `neo4j start`). By default, Neo4J will be available to us at `http://localhost:7474/`, and if everything goes well, we should see the panel below.

![](https://cloud.overment.com/2024-10-13/aidevs3_neo4j_dashboard-f2b4f95d-5.png)

Additionally, we'll also use the `neo4j-javascript-driver` to connect to Neo4J from the JavaScript/Node.js code.

The syntax of the Cypher language may be new to many of us, so it's worth using LLM for generating basic queries. I have written some of them in the `neo4j-101` example. After running it, several records will be added to the database, and then queries will display data in various configurations.

![](https://cloud.overment.com/2024-10-13/aidevs3_movies-36302f31-8.png)

Query examples include connections like "Who starred in movie X," "Movies in which actor Y starred" or "Which actors starred together in more than one movie."

![](https://cloud.overment.com/2024-10-13/aidevs3_neo4j_queries-ec2bfd60-a.png)

It should now be understandable what the capabilities of graph databases are and their advantages. However, all of the above queries rely on very specific document matches, and Neo4J's capabilities do not end there.

Neo4J also allows us to add a `vector index`, which will enable storing embeddings and searching documents. This is how a query about the content "Sauron" (the name of the main antagonist in Lord of the Rings) was correctly matched to the movie and actor "Hugo Weaving" playing Agent Smith in The Matrix and Elrond in the LOTR series.

![](https://cloud.overment.com/2024-10-13/aidevs3_lotr-d126277b-1.png)

In summary:

- Install Neo4J on your computer, add environment variables in the `.env` file, and run the `neo4j-101` example.
- Use LLM to generate Cypher language queries and ask several questions about the syntax to understand it at least at a basic level.
- Tip: to remove document content from the Neo4J database, run the query: "MATCH (n) DETACH DELETE n" and "DROP INDEX `movie_index`" and "DROP INDEX `actor_index`". You can do this in the Neo4J panel.

## Structuring Data

Preparing data for a graph database may involve structuring existing data (e.g., from the Internet) and/or building a graph from scratch as a result of interaction with an AI agent. As for building the graph itself, we can use LLM or our own domain-specific models.

Currently available are tools like [GraphRAG](https://microsoft.github.io/graphrag/) or methods available in LangChain, which offer the capability to convert unstructured text into a series of documents and their connections. The structured data can then be used to build context for a RAG system.

![](https://cloud.overment.com/2024-10-13/aidevs3_graphrag-f291e1a9-5.png)

Prompts listed [on the project page](https://microsoft.github.io/graphrag/prompt_tuning/overview/) deserve attention as they focus on:

- Listing entities and relationships between them
- Creating summaries describing entities and relationships
- Describing the state of the entity and relationships in different contexts
- Describing dependencies between entities

In other words, the goal of these operations is to extract structured information in such a way that the created documents are useful for the model's context.

It's easy to see that processing large amounts of content will be time-consuming and costly due to the need to execute many prompts for the same data sets. Currently, we can address the cost issue with prompt caching, but the problem of effective information extraction and connection remains.

Data transformation can occur based on a pre-determined schema (e.g., a list of book characters and the relationships between them), or have an open-ended character allowing the schema to be shaped with the discovery of further information. Ultimately, the strategy we choose will depend on the project's needs, and both have their pros and cons.

In practice, it quickly becomes apparent that too much freedom in creating documents and their relationships leads to content duplication and issues with later updates. Therefore, just like with databases and search engine indexes, it's necessary to plan a path considering the **delivery, organization, retrieval, and updating** of content — topics we've covered throughout the last lessons.

A compelling example that can serve as a point of reference shaping our idea of content structuring comes from the [funktio-ai-samples](https://github.com/JohannesJolkkonen/funktio-ai-samples) repository. Specifically, [in this notebook](https://github.com/JohannesJolkkonen/funktio-ai-samples/blob/main/knowledge-graph-demo/notebook.ipynb) you can find sample prompts responsible for individual stages of data processing for the graph database.

Below is an example of a prompt responsible for listing entities and their connections. While the general assumption is valid, our experiences from previous lessons indicate that such a task should be divided into at least two stages: retrieving the list of entities and, using a second prompt, describing dependencies for each one. This way, the model focuses on one activity, which usually leads to greater precision.

![](https://cloud.overment.com/2024-10-13/aidevs3_extrawcting-5253c3f3-f.png)

In summary:

- Working with a graph database involves two stages: **structuring data** and their subsequent **retrieval.**
- Data for a graph database must be converted into Nodes (Documents) + Edges (Connections) with their descriptive properties.
- Transformation will typically occur with the use of LLM and a series of prompts responsible for retrieving information and creating connections.
- Structured data is then directed to the graph database/vector index. This activity concludes the data structuring stage.
- The process of searching/loading information for LLM context occurs similarly to vector databases or classic search engines. However, in this case, the aim is to generate a Cypher query (or a series of queries) and connect the data into one context.

Let's proceed to the second stage, related to information retrieval.

## Knowledge Graphs and Retrieval Augmented Generation

When we have structured data and a graph database ready for searching, the next step is to connect it with LLM. Similar to the vector database, we need to generate queries and then format the returned results so that they can be appended to the system prompt's context.

Although LLMs can effectively generate SQL/Cypher queries, apart from situations of building solutions for our own needs, using this for searching the entire knowledge base is not a good idea due to potential Prompt Injection. Instead, the model should indicate areas and queries that we will programmatically transform into target queries, imposing our own restrictions, such as the level of access permissions to selected data.

In the `neo4j` example, I've prepared `Neo4jService` where there is a series of methods serving as an interface enabling communication between the model and the graph database. For example, below we have a query where LLM generates queries and a list of filters (which is also parsed elsewhere in the code to not give the model too much responsibility).

![](https://cloud.overment.com/2024-10-14/aidevs3_graph_interface-d1068a67-4.png)

Additionally, the model has three types of searches available (this results only from my decision):

- General search: retrieves documents from a given category
- Vector search: retrieves documents similar in meaning to the query with optional filtering by category
- Relational search: retrieves documents similar in meaning to the query but also considers the possibility of fetching information related to the result (e.g., articles about the specified tool).

The model, within a single query, can decide to make several inquiries from each category. However, instead of returning Cypher syntax, it only generates a JSON object with search parameters. Below we have an example of such an object created based on a request to "Find Neo4j and related videos."

![](https://cloud.overment.com/2024-10-14/aidevs3_graph_related_query-b1332ade-2.png)

The entire logic involves identifying whether the user's query requires interaction with the assistant's memory. Then, depending on the decision made, the data is either saved or read, and information about these actions is recorded in the context.

![](https://cloud.overment.com/2024-10-14/aidevs3_graph_rag-b2b32cd4-3.png)

Breaking it down into steps:

1. **Query analysis:** This is a prompt deciding what types of actions should be taken (READ|WRITE|ANSWER) by the assistant.
2. **Recalling:** This is a series of prompts in which the search strategy and queries for loading data into the context are described.
3. **Memorization:** If the model decides to save information, a prompt is triggered describing the new document and the logic that adds it to memory (in our example, I didn't extend it to create relationships between documents).
4. **Response:** Based on the retrieved context, a response is generated.

This is a simple example of GraphRAG implementation, illustrating the main interactions between the user, the model, and the data source. However, if we decided to use it, it would be necessary to expand it with logic for connecting records and verifying whether records are **duplicated**.

We also see that the overall RAG system scheme is similar to what we discussed in previous lessons on hybrid search. However, here we gain new possibilities of querying the knowledge base, but we also have to deal with new problems such as building proper connections or navigating the graph structure.

## Summary

Graph databases are undoubtedly an important element of generative applications and should be considered when deciding on a set of tools. It is also good to include them on your development map and acquiring new skills, although in this area, support from LLM proves very helpful.

I don't yet have much practical experience in working with graph databases, and looking at materials available online in the area of connecting graphs with LLM, it is still quite early. However, a good source of knowledge is the official Neo4j blog, as well as a less official source in the form of the [NodusLabs](https://www.youtube.com/@noduslabs/videos) channel. Although both are aimed at their own products, among the published materials, you can find many valuable tips on building your own tools.

Besides that, I also mentioned GraphRAG and integrations available in LangChain or other frameworks. Even our `neo4j` example shows that we usually want to tailor interaction with the graph to our own needs, but sometimes ready-made solutions may prove more useful, for example, due to ease of implementation.

If you are to take only one thing from this lesson, try to combine the `neo4j-101` example and then save and read several sets of your own data. Also, use LLM to explain Cypher syntax and generate sample queries.

Good luck!