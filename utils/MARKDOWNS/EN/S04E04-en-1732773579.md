![](https://cloud.overment.com/S04E04-1732717129.png)

In the previous lesson, we focused on knowledge sources for LLM in the form of files and web content. I also mentioned that external services with API can be a source of information. Besides, we can use this not only to retrieve information but also to **take actions**.

Therefore, in this lesson, we will create another set of tools to connect the model to the external world. Through examples, we will see how crucial the consistency of data exchange format is and how one can facilitate tool building for personal needs using no-code solutions.

The discussed examples are located in the `tools` directory, including:

- **Google Maps:** Allows precise route directions and loading information about places.
- **Spotify:** Enables searching for tracks, albums, and playlists, as well as playing music on an available device.
- **Resend:** Enables sending emails using the [resend](https://resend.com) platform.
- **Speak:** (MacOS only) allows playing a voice message using the `say` command.

Additionally, the code includes classes for SMS API, Google Calendar, and YouTube (due to Google’s privacy policy changes, this class operates only on a local computer).

> IMPORTANT: Given the need for accounts and API keys for the services mentioned above, consider their activation optional. This lesson is primarily about **schemas and practices for tool creation**, not specific implementations that I’m presenting.

## Permissions and Availability

In lesson S00E03 — API and practically every example, permissions granted to the model and AI agents were discussed. Until now, we almost always dealt with examples of **data reading**.

This time we will proceed to tools in which a possible error could result in irreversible outcomes (e.g., sending an email) or generate unnecessary difficulties. Therefore, as in the `websearch` example, we will focus on programming constraints that will catch potential errors in responses or simply **leave no room for them**.

Looking at the tools we will go through, consider the technological stack you use or your company uses. Check if the solutions you work with offer API access and what methods and response formats are available. Then ask yourself: **how can you use them to facilitate, optimize, or automate selected processes**.

Also, consider the non-deterministic nature of models. In situations where you need 100% precision, using models might not be a good idea. However, it might turn out that non-deterministic responses can be valuable.

Ultimately, **always ensure to limit the model’s permissions to only what is necessary**. If this is not possible and LLM assistance is still needed, include a human verification stage.

## Interface

Even though for tools like Google Maps, we are not talking about document processing, we will still use document structures (content + metadata) as input/output data. This will maintain consistency between tools and, for example:

- The Google Maps tool will be able to process a list of locations loaded from selected websites or PDF files, or audio recordings.
- The Google Calendar tool will be able to receive a list of emails from which meetings will be created in the calendar.
- The Resend tool will receive reports to send private newsletters or messages to selected individuals (e.g., a team).

Such configurations can also involve the engagement of several tools between which we will pass data.

We will return data in the form of documents both in case of success and error. This way, the agent will receive information not only that the task failed but also about the error details, usually leading to its automatic resolution.

![](https://cloud.overment.com/2024-10-21/aidevs3_messages-9f5ae274-5.png)

The document structure does not have to be exactly like in my examples. The key is maintaining consistency and flexibility so that the same format is retained for each tool.

## No-Code Tools

For services like Google Calendar, Google Maps, or Spotify, we require authorization using OAuth 2.0. Using it usually requires reading the documentation and publishing endpoints responsible for redirecting to the login page and receiving tokens needed for further queries.

Programmatic connection to tools usually brings benefits, but sometimes the time needed to implement them is not justified. For example, if we are creating an agent to manage an email inbox to perform simple operations like creating a draft message, building the entire integration from scratch makes no sense.

In such situations, it is worth using no-code platforms like [make.com](https://www.make.com/). With Make, we can create a scenario starting and ending with a Webhook module. As a result, this automation will trigger when we send an HTTP request to the address generated in the "Custom Webhook" module. In response, we will receive everything included in the Webhook Response module.

![](https://cloud.overment.com/2024-10-21/aidevs3_make_webhooks-60d51b75-1.png)

Working with Make goes beyond our training scope, so I refer you to the materials on the [Make Academy](https://academy.make.com/collections) site. However, I will add a few key tips:

- The webhook must be secured against accidental invocation. In the advanced settings of the module, we can activate the option to capture HTTP headers to read the Authorization header. Details on this can be found [here](https://community.make.com/t/incoming-webhook-authentication/15219/8).
- The **webhook response** module allows manual entry of a JSON object, but this is not recommended due to special character handling. Instead, always use the Create JSON module, which lets you define the object structure, from which a JSON String will be generated. An example of this is shown below.

![](https://cloud.overment.com/2024-10-21/aidevs3_json_response-c8518477-f.png)

Due to LLM's development, I increasingly recommend fewer no-code solutions because creating API connections, including OAuth 2.0 handling, is becoming easier. We just need to ensure to paste the documentation content and/or examples from the SDK into the system message of the model, and the model will implement the entire logic for us without major issues.

However, it is worth staying with no-code tools in the situation described above (our solutions where we don’t have much time) or when:

- We want to connect many services together.
- We aim for the ability to easily edit the logic without opening the code.
- We want to engage non-programming/persons who can't use generated code.
- We need a one-time solution or are in the prototype stage.
- We want to avoid maintaining integration, e.g., due to changing API.

Generally speaking, **LLM's increasing abilities to generate code make the benefits of quick logic implementation using no-code smaller**. However, no-code tools' value remains, although their role shifts.

## Google Maps

Google Maps is available by creating an app on [Google Cloud](https://console.developers.google.com/) or through native integration in make.com (though here, we still need identifiers generated in Google Cloud). Available actions include loading information about places and determining route directions to a destination.

For determining route information, the user will usually provide incomplete data, like: "how long will it take to get to Warsaw?" or "how much time do I need to get home?".

For such queries, the Google Maps API will not be very helpful. But if documents containing information on **where the user currently is** and **where "home" is** appear in context, finding the route will be possible.

In lesson S01E02 — Context, I demonstrated a similar example where an agent 'started favorite music' without specifying an artist.

Therefore, for each tool, we must consider the queries and scenarios we wish to handle. We should not think of **specific cases** but of **general principles**.

For example, in the application code, there is no mention that the agent needs to 'find out what the user's favorite music is.' Instead, the agent asks a series of questions to better understand **the user's intention**. Thus, it is about speculative questioning ([Speculative RAG](https://arxiv.org/pdf/2407.08223)) and trying to clarify ambiguities and find missing information.

LLM is very helpful in such situations, which, based on a few examples, is able to help us with **generalization** and **determining schemas**. Below is a fragment of my discussion (with typos) where, after describing the problem, I ask for a broad perspective rather than a specific situation.

So the lesson from this tool is as follows:

- The system must strive to discover/acquire missing information, using long-term memory and/or external services.
- Problem-solving should be based on **schemas**, **rules**, and **principles**, not individual cases, which will be too many to address all.

## Sending Messages

Sending emails, private messages, or SMS created by LLM is often cited as a business need in the context of sales and marketing processes. It is almost never a good idea (though such processes work on a large scale and are usually considered 'cost-effective'). Leaving aside the ethical aspects of such solutions, the ability to communicate through various channels is useful.

We know that some tasks performed by the agent will be asynchronous and often will take several minutes or several hours. Among them will also be actions triggered in response to an event or set time.

Therefore, it is worth considering connecting to services like:

- [Resend](https://resend.com) or any alternative enabling sending transactional emails.
- [SMSAPI](https://www.smsapi.pl/) or an alternative (e.g., Twilio) allowing SMS sending.
- [Slack](https://slack.com/) or another communicator with an API.

However, these services **should not be used for sending mass messages**. Furthermore, the **contact list should be limited** or directly set to just one address — ours.

Besides limits, the biggest challenge is ensuring that LLM can generate content that will actually be valuable to us. Unfortunately, it usually is not, as shown in the example of a message in response to the request for "a list of movies featuring Keanu Reeves."

However, after adjusting the prompt to our needs and personal preferences, we achieve a result drastically different from the previous one. The tone of the message, conciseness, and above all, **fully completing the task** characterize messages written by a human. Most importantly — such communication carries real value.
In the case of `tools/ResendService`, we have only one prompt responsible for writing the message content. However, using the `web` example, we know that we can expand the logic to a series of prompts that create a comprehensive message. If necessary, we can also include the use of an HTML template to prepare a fully-fledged newsletter.

The conclusion from this tool is as follows:

- Sending messages via messengers and email should be possible but very limited. The situation where an LLM decides to send private correspondence to a random email address is very possible.
- The way the content is formatted and recorded should be tailored using prompts and examples to potentially limit the model's default behavior of generating very general content.
- Since we will not be able to make corrections to the message content, we need to spend more time matching the prompt.

The following prompt was shaped with the help of LLM, using a meta-prompt from lesson S00E02 — Prompt Engineering. However, creating such instruction is not automatic and requires several iterations in which we jointly shape subsequent behaviors with the model.

Similarly to other tools, in response, we send a document with the message content and the status of the action or information about its failure.

Actions related to communication should also include the rules for using them. For example, expanded messages should be sent via email, and urgent messages requiring immediate action should go to SMS. 
## Entertainment

Not all integrations will rely on standardized interfaces and ready-to-use APIs. Sometimes we will have to find 'creative' solutions to seemingly unsolvable or difficult problems for our own needs.

One such integration might be a notification in the form of a voice message triggered on our computer. One solution is to use a bash script and the `say` command (macOS) or tools that allow playing audio files (e.g., `afplay`). Such a command should be available remotely (e.g., via [ngrok](https://ngrok.com/)).

Since this action is available exclusively on macOS, we won't spend much time on it. Besides, its implementation is very simple and boils down to running one command.

I have been using voice notifications for a long time, which work great as reminders and for informing about completed tasks.

Another example of an action I use for entertainment is integration with Spotify. In previous editions of AI_devs, I used the Make automation scenario for this purpose. Now, thanks to logic generated by LLM, I have established a direct connection with the API.

Thanks to this, such a scenario:

Has been replaced with a single class `tools/SpotifyService`, and finding and playing a song is reduced to calling the function `await assistantService.playMusic('Title, artist');`. This also confirms what I wrote above about no-code tools and their changing role in the face of increasingly better language models.

> Important: To run the Spotify tool, you must create an application on [developer.spotify.com](https://developer.spotify.com/dashboard) and fill in the keys in the .env file. Then, after starting the application, go to the /spotify/auth address (our localhost must be accessible on the Internet, and the endpoint /spotify/callback added in the Spotify developer panel). This will append tokens to the .env file (not recommended for production, but in this case, we don't have a database, so we must use it), and Spotify will be available after restarting the server.

The example of Spotify integration also contains several interesting suggestions, but it is based on similar patterns as the Google Maps example.

Specifically, user queries can be very general and relate to things like:

- Play the track that was playing when Memphis saw Eleanor for the first time in Gone in 60 Seconds.

This refers to a specific scene in the movie "Gone in 60 Seconds". Despite the lack of a song title, the model, using its base knowledge, identifies it correctly.

Spotify's database is not complete, and sometimes contains several variants of the same track. Therefore, in the `playMusic` action shown below, I not only use a search engine (`this.searchMusic`), but also use the `spotifyPlayPrompt` prompt, which is tasked with making a **decision** about which record from the search results to play.

Spotify search results contain many detailed information, which can be ignored from our integration's perspective. Therefore, I use a helper function `formatMusicSearchResults` to select only those properties that are relevant. This is also driven by reducing 'noise' and aiming to keep the model's attention on the task.

Conclusions:

- Creating tools for an agent can also tap into our hobbies or interests. Even if their usefulness is questionable, building them allows us to gain experience useful in other situations.
- Creative problem-solving, especially when we are building something for our personal use or internally within a company, is highly recommended. Not all applications and services have official APIs, and sometimes we need to look for alternative paths.
- Once again, we found that building an intermediary layer between the LLM and our application is advisable. This allows us to maintain control between data exchange format and query transformation.
## Best Practices

Compiling best practices on building model tools:

- **One prompt = one problem**: complex tasks should be divided into smaller steps, and the model at a given moment must receive a minimum of information.
- **Generalization of the problem**: problems have their cause that should be discovered and addressed. If the prompt doesn't work in situation X, don't try to solve it but find its reason or pattern according to which the model operates.
- **Help from the model**: in planning, writing code, writing prompts, generating test data sets, debugging — **always work together with the model**.
- **Series of actions:** tools should be designed to allow multiple queries to be executed simultaneously. This way, the model will be able to gather all the necessary information at once, positively affecting overall efficiency.
- **Common interface**: the value of connecting the model with tools is not just about their direct connection but about the ability to connect many tools, which the model accesses when necessary.
- **Complete information**: tools must always return complete information on obtained data or errors that occurred. If the data is not complete and correctly marked, the agent will not be able to use it.
- **Limitations:** relieving the model from making decisions should be a priority not only for system stability but also for its performance.
- **Simplifications:** where possible, it's worth applying simplifications either in the form of no-code tools or ready-made solutions that allow us to focus on other system areas.
- **Observation:** all steps related to using tools should be logged and/or recorded in a database. These information should be accessible to both humans and the system itself (although this depends on its purpose). Collected data will be useful over time for building test data sets and further shaping prompts.
## Summary

Integrating LLM with the services and devices around us by building tools in such a way that the model can freely use them constitutes another fundamental element of AI agents.

If you are to take only one thing away from this lesson, look at the examples of tool implementations from the `tools` directory. Then, choose **a tool, service, or device** from your environment and check how it looks in terms of API availability. Choose one that offers integration potential and plan actions that might be useful for LLM.

Also, consider how an agent equipped with such a tool could add value to you or support internal company processes. Also, consider the possibility of connection with other tools and share your thoughts in the comments.