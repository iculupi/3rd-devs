![](https://cloud.overment.com/s05e05-1730924179.png)

## By Way of Introduction

Anyone who participated in previous editions of AI_devs or follows me on X, Instagram, or LinkedIn knows that "Alice," which appears in the lesson content, also has a second version available exclusively to me. This stems from the fact that the level of personalization of this project is so high that it was difficult for me to share it...

...until today.

The journey in AI_devs has led us to a point where key aspects related to tool creation, data work, various file formats, and developing agent logic have become quite understandable. Now it would be good to look at this from both the broad perspective of a somewhat larger project, and the details.

An important variable here is also the fact that thanks to collaboration with Cursor, even if you work in another technology or focus on areas other than backend applications daily, you will still be able to thoroughly familiarize yourself with my code. Recent weeks, as well as people working in Python, .NET, or simply in front-end areas or other specialties, have confirmed this possibility.

Therefore, in the last lesson of AI_devs 3, we will focus on discussing a system that **connects all the previous concepts** and is intended to help you "connect the dots" or at least show how you can apply the knowledge from AI_devs 3 in practice.
## AI_devs 3

The lessons of AI_devs 3 have taken us through **everything we currently know about models**, techniques **interacting with them via APIs**, **building user interfaces**, **structuring and processing content**, and **building tools** with large language models in mind.

Each example took the form of a "module" (this is a metaphor, as they don't meet the module definition) which typically focused **only on one task**. Thanks to this, we gradually noticed that we could combine them with each other in practically any order. However, in the last lessons, we also learned how we could expand them and make them play the role of agents cooperating with each other.

However, I said that to build a team of agents, it's worth mastering the construction of at least one of them well.

"Alice" in my private version is a project I've been developing since December 2022. Its form is a continuation of my 'avatars' team concept, which I started a few years earlier when I only had code and no-code tools at my disposal.

During all this time, Alice has developed. The capabilities of language models increased, and new tools appeared regularly. My experience also grew. So I decided that AI_devs 3 is a great opportunity not only to create another version but also to share the project code — "Alice AGI."

> "AGI" should obviously be taken with a grain of salt and not literally, although the current capabilities of the project are quite a good foretaste of how our daily lives might look in some time.

![](https://cloud.overment.com/2024-12-03/aidevs3_agi-3c33ec7b-a.png)

## Before We Begin

I'm sharing the "Alice AGI" project on my GitHub, but I don't plan to develop it in an Open Source form or publish updates while maintaining backward compatibility. This project will therefore retain its private character. Of course, the "Issues" section can serve for the exchange of ideas or suggestions, but nothing more.

Naturally, there are still many smaller and larger bugs in the project, although I've been successfully using the main functionalities of the new version for about 4 weeks.

The primary goal of this project for this lesson is **to show how all the discussed AI_devs 3 concepts can be combined into a whole**.

So it is a wealth of knowledge (at least according to me) not only about what I talked about in the lessons but also about things I didn't have the opportunity to discuss.
## Costs and Response Time

For some reason, when chatting with another person, waiting a few or several minutes for a response is fully acceptable to us. However, we have completely different expectations of applications and language models.

It's good to know that in the current form of Alice AGI, the response time rarely drops below one minute. Exceptions are queries classified as 'fast track,' which do not require engaging the agent's logic.

![](https://cloud.overment.com/2024-12-03/aidevs3_latency-78ed28ba-b.png)

It's similar with costs, which currently reach $0.3 per query. Of course, there's huge potential for optimization and a switch to models like Claude 3.5 Haiku or GPT-4o-mini, which would also reduce the response time for some tasks.

![](https://cloud.overment.com/2024-12-03/aidevs3_costs-1bfbc1f7-6.png)

So it's worth keeping in mind from the outset that system complexity translates into significantly higher response time and relatively high costs. It may turn out that using such a solution will be unprofitable for you, or that **it’s worth building one that will largely rely on open-source models.**

Because no one said that every agent must be built exactly this way, and all my assumptions are correct.
## Main Concept

The Alice AGI concept is simple and **aims for the most fluid conversation possible with an application that knows about me and can use the tools I work with.** Below, there is an example of such a conversation, resulting in a new entry being added to my task list.

![](https://cloud.overment.com/2024-12-04/aidevs3_chat-5ae58c40-0.png)

In the future, I can return to this topic, which may happen **in a new conversation.** The history of previous messages doesn't matter here, as the necessary information is loaded both from my task list in Linear and the model's long-term memory. Below, we see that Alice indeed talks about buying gifts and recalls Kate's interests.

![](https://cloud.overment.com/2024-12-04/aidevs3_gifts-d84c21af-7.png)

The above question triggered the logic below, where we see the connection to the task list and loading information from long-term memory. What we see below is of course [Langfuse](https://langfuse.com/), which we discussed in the first weeks of AI_devs.

![](https://cloud.overment.com/2024-12-04/aidevs3_report-cf026e82-0.png)

The conversation can naturally continue, and below, we see a response generated based on an Internet search, as the model does not inherently know about the "Arc Ultra" product.

![](https://cloud.overment.com/2024-12-04/aidevs3_ideas-96f7f822-0.png)

However, it may not always be a fully fluid conversation, as we know the model cannot guess everything. Besides, we are limited by the available tools or even the possibility of interacting with them from the code level — both of these topics were discussed in AI_devs 3 lessons.

At this point, a question may arise: **why use these tools with chat when you can do it yourself?**

First of all, one doesn't exclude the other. However, the ability to recall information from several sources or add several entries with one message is often simpler than switching between tools. Secondly, message sending is also available from automation or external services, as mentioned in the lessons. Furthermore, in the post "[How I Work with LLM?](https://bravecourses.circle.so/c/dyskusje-ai3/jak-pracuje-z-ai-material-bonusowy?login_token=WjXMQxUS24pwtFwCdZ84ejK5eKNrBk2tLX7c#comment_wrapper_51468273)" I also mentioned that these same capabilities are available to me on Slack, on my watch, or in my car.

![](https://cloud.overment.com/2024-12-04/aidevs3_interfaces-84314d33-9.png)

So let's see how all this works.
## Tool Set

Despite the growing popularity of frameworks that are already appearing in job postings from companies like Amazon, Cloudflare, or Apple, I've decided to work with [Vercel AI SDK](https://sdk.vercel.ai) to connect with OpenAI and Anthropic models. Meanwhile, the screenshot below signals the possible rise of frameworks in the future. Therefore, it's worth monitoring their development, testing new versions, and after completing AI_devs, considering familiarizing yourself with LangGraph, which some of you commented deserves attention.

![](https://cloud.overment.com/2024-12-04/aidevs3_crew-0d211d9a-9.png)

Although it's "just" an SDK, I've already encountered limitations that required bypassing it when handling audio. However, the project is still very well maintained, and so far, I consider the AI SDK choice as the right one. At the same time, implementing the rest of the logic was simple enough that I see no reason to currently use frameworks that would do it for me.

The main application code is being created in Node.js, using the [hono.dev](https://hono.dev/) framework, which I am working with for the first time. Similarly, this is my first time working with SQLite combined with [Drizzle ORM](https://orm.drizzle.team/). These decisions result in a very small project dependency list, where most of the libraries are related to the tools used by the agent.

Therefore, both the framework, the database, and the application directory structure are suited for a small project, as that is its premise. I aim for the whole to be as simple as possible but based on solid foundations (though in my opinion, those are still debatable at the moment).

![](https://cloud.overment.com/2024-12-04/aidevs3_structure-315b6ae2-4.png)

So we have several configuration files, database migration files, middleware functions, directories with prompts, paths, services, and a few auxiliary functions. Most of the action naturally takes place in actions assigned to **paths** (routes directory) and respective **services**. Quite significant are also the **middleware** functions that handle query transformation from OpenAI/Anthropic formats to Vercel AI SDK format.

And, of course, regarding developing prompts and observing the application, Langfuse and Promptfoo come into play here (although the latter isn't plugged in yet). The integration itself takes place directly through the official SDK, providing control over monitored events.

![](https://cloud.overment.com/2024-12-04/aidevs3_langfuse-902181b8-5.png)

I haven't decided yet to plug prompts into Langfuse, but I don't rule it out in the future. For now, the prompts present in the project files seem a sufficient solution.
## Main Logic

The logic of Alice AGI is a modified version of the agent logic example, which we discussed in several of the last lessons.

However, it's worth viewing it with a bit of distance, as it relies solely on my experience, and at this stage, I don't have publications or examples that can support my assumptions.

So it's hard for me to determine the system's capabilities at this stage, although recent weeks have shown me that they are much better than what I worked with so far.

![](https://camo.githubusercontent.com/f3f679cbbf018892d56cf462707a1b8b5d0ad2097dffd66b5134b59c1a90fa4c/68747470733a2f2f636c6f75642e6f7665726d656e742e636f6d2f323032342d31322d30332f6c6f6769632d30303538313362642d392e706e67)

So here we have:

- The main `chat` endpoint, which receives and sends data in the OpenAI format. It also supports an additional `conversation_uuid` property, mentioned in the context of thread recognition.
- The "fast track" stage is the query classification regarding whether the response requires activating the full agent logic. This makes conversation easier, as not every message requires taking new actions.
- The "observe" phase involves compressing information from the environment and the user profile, as well as sketching a preliminary action plan. 
- The "reasoning loop" phase contains almost the same logic as discussed in the `assistant` example. It involves task planning and the actions that need to be taken in relation to them.
- The "response" phase is simply generating an answer based on all the available information.

This is relatively simple logic that allows the agent to connect with a set of tools, which we also discussed in AI_devs 3. However, at this stage, I want nothing to be left unclear.

Below is our main endpoint. The entire logic boils down to:

- Establishing the state of the conversation, i.e., loading all necessary data.
- Classifying the query regarding whether it can be addressed without the "thinking" phase.
- Generating a response either in the form of a simple answer or streaming.

Additionally, before the above action is initiated, the data passes through a set of "middleware" functions. They are responsible, among other things, for securing paths against too many queries and unauthorized access. Also, all queries (with a few exceptions) must have the `Authorization` header set to `Bearer API_KEY` (the value of this key should be set in the .env file to any value).

What will soon change here concerns the way information streaming starts to begin **immediately**. This relates to one of the latest updates to the AI SDK "non-blocking data streams" which I mentioned in lesson S05E04.

Such streaming, or switching to event-based communication, is important both because of extended response times and the overall ability to observe and potentially influence the process.

Because if we look at the `think` method, its execution takes the most time, and there we might need **to interrupt execution** or **contact the user**.

Since we're at the `thinking` phase, the following queries operate inside it:

- **observe**: Two prompts are executed here that extract only significant information from the **environment** and **user profile**. The idea is to pull only those data from many available, that are crucial at the moment.
- **draft**: Two prompts are also executed here. One generates notes on potentially vital memory areas to search, and the other does the same with the list of tools. In other words, the agent preliminarily considers what to do. This is important because such reflection is usually correct and strengthens the emphasis on taking those actions.
- **plan**: The planning phase aims to generate a **task list** necessary to provide an answer.
- **next**: Here the **next action** is selected within the chosen task by the model.
- **use**: Involves generating data necessary to trigger an action. In the case of Function Calling, this would be generating arguments needed to run the function. In my case, it is simply a regular JSON object.
- **act**: Here, the action is executed, and its result is saved in the database, affecting the execution of the next loop iteration.

Classically, the `while` loop is programmatically limited in such a way that it will be interrupted when the `final_answer` action is selected or when the allowable number of steps is exceeded.

The above approach works great for tasks where the plan can be immediately established, but it still faces problems with scenarios that require a significant change in approach during execution. These are relatively rare scenarios occurring in the most complex tasks but they do happen.
## API

The API primarily relies on the main endpoint `/api/agi/chat`, but it is not the only address to which we can direct queries.

- `POST /api/conversation/new`: allows the creation of a new conversation thread and returns its identifier. This is useful in the context of integration with an external interface, e.g., Siri Shortcuts.
- `GET /api/conversation`: retrieves the conversation that took place within the last 15 minutes. This is also useful in the context of integration with an external interface. The condition here is to exclude interactions that were not automatically triggered, e.g., for automation or task scheduling.
- `GET /api/auth/spotify/authorize`: allows connection to Spotify via oAuth 2.0.
- `GET /api/auth/google/authorize`: allows connection to Google API (Calendar / YouTube / Gmail) via oAuth 2.0.
- `GET /api/files/:uuid`: allows loading the content of a file/document based on its UUID.
- `POST /api/upload`: allows uploading a file and associating it with a conversation.
- `POST /api/tools/memory`: allows adding a new memory without engaging the full logic of the agent.
- `POST /api/tools/memory/search`: allows access to the agent's memory without engaging its full logic.
- `PATCH /api/tools/memory/:uuid`: allows updating a selected memory.

Some of the remaining tools also have their own endpoints, but I will not list them here as they do not play a significant role. The key is that some assistant skills are directly accessible. From the level of automation or scripts that precisely deliver some information, there's no sense in directing the query to the main endpoint.

Conversely, user inquiries are always directed to `/api/agi/chat` and there the agent decides what needs to be done with them.
## Database

The database structure looks quite familiar compared to what we discussed in the lessons. However, here we have a few additional tables, as seen in the diagram below (open it in a new tab):

- `users`: It's a classic table storing user data. What's unusual here are the fields **environment** (JSON) and **context** (text), and their role is to store current data about the environment and general user profile, which I mentioned a moment ago.
- `conversations`: It's a list of interactions assigned to a user and a list of messages. Extracting this table is significant because you can start a thread before the user's interaction. For example, when uploading files to a new conversation, we create a thread to which the user will be able to send messages later.
- `messages`: Here, we have a list of messages, but they also support the ability to store images. They're also linked with the `documents` table, making it possible to associate files with a specific message.
- `categories & memories`: It's the basic structure of memories. Each of the memories is also linked with the `documents` table, whose entries are (but not always) indexed in search engines.
- `tools`: It's a list of tools, their descriptions, and execution instructions. Tools are assigned to actions.
- `tasks`: It's a list of tasks that need to be performed to provide an answer. The result of the task takes the form of an entry in the `documents` table.
- `actions`: It's a list of actions that need to be performed **within one of the tasks**. The result of the action takes the form of an entry in the `documents` table.
- `jobs`: It's a list of tasks triggered according to a schedule. Here, there's a link with the `tasks` table and indirectly with `conversations`. Thus, when the right moment comes, the system sends a message 'to itself' and undertakes the commissioned task.

It's clear here how important the `documents` table is. Its entries appear practically everywhere, but we can use them consistently. It doesn't matter if a "document" is a file, the result of an action, or an error message — each can be processed according to the same principles.

The general structure of the database in its current form, however, has at least a few drawbacks and smaller inconsistencies.

For instance, I wonder if `tasks` should have a link with the conversation or with `messages`. The reason is that without this, I can't reconstruct the full history of the interactions. Currently, it’s not a problem, but it can become one in the most complex tasks. I'm also not convinced about the document structure, but again, currently, I don't have an issue with it.

The conclusion is that the current database structure is very flexible, yet relatively simple and generic. It may serve as a foundation for various types of agents, although it doesn’t anticipate `agent-agent` interactions in its present form.
## Available Tools

At the moment, Alice AGI has access to 14 tools and 33 skills (specifically 37, but we have two kinds of searches). The tools include the most basic ones, such as **memory, internet access, task lists, or calendar**. There’s also the possibility to process files and access services allowing for sending emails or controlling music.

When it comes to tools, we rely on exactly the same concepts we discussed. Besides minor housekeeping, it's code derived directly from the AI_devs 3 examples repository.

Connecting a new tool involves a few steps here.

1. Creating a service in the `src/services` directory modeled after the existing ones. The key function there is `execute`, which accepts `action name` and `payload`. There's a good example in `spotify.service.ts`.

2. Then the service must be added in the `config/tools.config.ts` file because this way it will be available in the `act` method from the `ai.service.ts` file.

3. An entry must be added to the database in the `tools` table, likewise modeled after the existing ones. We know as well that there — the name must be short and unique, the description must explain when to use this tool, and the instruction must describe how to generate data to trigger it.

And nothing more is essentially needed to add new tools. Of course, within one tool, multiple actions can be included, which is strongly recommended. Therefore, it’s worth getting acquainted with the already existing tools to make a decision on further steps based on them.

So summarizing the main logic issue, **Alice AGI is really a combination of two things — the tools we built in the lessons and the agent logic we discussed this week.**

## Project Launch

Details about launching the project have been described by me in the README.md file. In short, you need to:

- download the project repository: [download](https://github.com/iceener/ai)
- install dependencies: `bun install`
- migrate the database: `bun migrate`
- fill it with initial data: `bun seed` (these can be adjusted in the `seed.ts` file)
- copy the `.env-example` file and rename it to `.env`
- inside the `.env` file set `API_KEY` to any value, and API keys for OpenAI, Anthropic, and all variables for Langfuse, Qdrant, Algolia. The remaining variables are optional as they're directly associated with tools that need to be adjusted to one's needs, or new own tools need to be created.

>> Configuration <<  

Therefore, launching the project itself is not particularly complicated. However, it is good to familiarize oneself with the structure of the tools and the agent logic. I attach a set of sample integrations for a reason, as they are a good point of reference.

After launching the project, we'll still need a graphical interface. Here it's possible to connect under the Alice application (a 3-month trial for AI_devs 3 is available [here](https://bravecourses.circle.so/c/dyskusje-ai3/dostep-do-alice?login_token=6b8Zfn2abL7iLfJvhWnbgpgCmCmyQFdk28Qz#comment_wrapper_51552013)) or through the Tauri application template that I published [here](https://bravecourses.circle.so/c/dyskusje-ai3/wlasna-aplikacja-desktopowa-szablon-tauri).

In the video below, I demonstrate the capabilities of Alice AGI in using tools. It also clearly shows the current limitations of language models (e.g., operating speed), but also the possibilities related to the processing of commands written in natural language.

>> Interface <<

Alice AGI clearly shows that building a specialized agent moving around a specified area is now fully possible. It looks similar in production applications, though here the number of restrictions we will want to impose on the system will be appropriately greater because the number of variables influencing its operation grows very fast.
## Alice AGI in Practice

Alice AGI is a sandbox project. It can be used for learning and exploring model capabilities, or its scope can be predetermined, implemented, and simply watched as it works for us. In my case, it's both scenarios, as the project constantly evolves, but increasingly large functional aspects remain with me permanently.

In my case, I permanently use:

- Voice task addition, especially when I'm away from home. The ability to dictate a message that turns into tasks still impresses me.
- Adding events to the calendar via a Slack message when I can't speak freely due to noise or, conversely, silence, but in the presence of others.
- Long-term memory — there's a bit of privacy here (but not excessively). Entries about the books I've read, projects conducted, personality tests, or casual notes allow for quality discussions that feel like there's someone on the other side who knows me. Although discussing certain topics still feels like talking to a bot, often among the exchanged messages, suggestions appear that I wouldn't have thought of. I'm currently modifying the memory module due to inspiration from the AGI Memory project.
- Automations operating on a schedule or events. These are actions connected to my task list, folders on Google Drive, or even the moment Bluetooth connects to my car. Depending on the context, I receive a message, or some action simply activates. An example might be collaborating with the person responsible for editing parts of my videos — there, communication, tasks, and billing are fully managed by Alice.
- And of course, fun. It's no coincidence that Spotify, lighting, or car actions via API featured so prominently in AI_devs. I believe that it's these most absurd actions, which seem useless at first glance, that taught me the most.

Of course, not everything is always perfect, but the biggest issues are related to three areas — unavailability of model APIs and/or external services, internet unavailability during travel or in some places, like the garage, missing functionalities, or limitations of existing ones.

Language model limitations practically no longer occur, but I'm referring to situations where I am the user of this system. Handing it over to other people is restricted to single actions or skills (e.g., translating or editing a document based on a URL in Notion). The reason is that such an "open" system is still challenging to tailor to the needs of any user. Even calendar integration for someone working on multiple accounts is a whole different topic than single calendar integration.

Both collaborating with the existing versions of Alice AGI and the construction itself clearly show me that:

- model development continues and I don't see a slowdown here
- most indicators like larger context or falling prices are less significant than marketing messages claim
- we still know practically nothing about the nature of language models. I often find myself on unconventional paths and am constantly surprised by what is possible or the opposite
- it's worth observing the people behind this technology, tools, and research. However, one must unconditionally remember that these are just people, and over even the past two years, a large portion of commonly accepted 'truths' has been challenged or proven wrong from the start
- nothing provides greater value than independent exploration and building, combined with exchanging ideas among like-minded individuals

Ultimately, I don't know if the Alice AGI project or even just the idea will stay with you long-term. However, I hope the recent weeks were valuable to you and you find practical application of this knowledge and skills in your daily life.
## Another Chapter

Looking at the last two years of generative AI development, we see that initially, we could ask for answers, then for actions, and then series of actions.

Today, we can fairly freely converse with the model and even set it goals that it can achieve independently. However, this requires understanding the nature of models as well as programming knowledge. This allows for designing a system in such a way that it can perform its tasks predictably or effectively enough to make its use meaningful.

AI_devs 3 has just ended. This means that a new chapter in the history of collaboration with Artificial Intelligence is now beginning, a part of which you will write.

I think everyone will agree with me now that generative AI is already an integral part of our work. It's also clear that, at least for now, building comprehensive systems is still only possible through **combining our experience with the possibilities of new technologies**. And even if today we still encounter barriers directly resulting from the capabilities of current models, even yesterday's release of `o1` suggests that some of these will soon disappear, but there's little indication that this will happen "tomorrow".

---

I wholeheartedly thank you for participating in AI_devs 3 ♥️ For me, conducting this training is an honor, especially considering that your presence here is a sign of trust in me, my knowledge, skills, and experiences for which I am grateful to you.

I realize that not everything was perfect in this edition and that there were minor or major challenges here and there. However, the fact that you are reading these words suggests that the material was interesting enough to be worth going through.

Finally, I have a request for you to sign up on our "Wall of Love" using [this form](https://app.easy.tools/review-ask/68a7fc7cc8444718ab3f0469f3eb9d8c?lang=pl). If you also want to leave suggestions and/or feedback about the training, we will soon send a dedicated survey on this matter.

![](https://cloud.overment.com/2024-12-05/aidevs3_love-b2f343f1-c.png)

Special thanks also go to:

- Jakub and Mateusz — for developing the storyline and task system as well as creating an extraordinary atmosphere during the organization of the largest online training in my history.
- Paweł Dulak — for remarkable engagement and support during the training handling and task testing
- Paula Skrzypecka — for a engaging and humorous meeting that shed light on responsible implementation of systems involving GenAI
- Michał Furmankiewicz — for a great meeting that showed that GenAI systems are already being implemented in large organizations
- Mariusz Korzekwa, Dominik Fudziekiwicz, and Paweł Manowiecki — for initiatives in the form of unofficial Discord and OpenAI Devs meetups
- Mateusz Szmigiel, Mateusz Tomkiewicz, Bartek Karalus, Piotr Brzyski — for initiatives of AI_devs meetings in various cities
- The brave.courses team — for flawless organization of the training and taking care of even the smallest promotional details, external collaborations, events, graphic presentation, and all formalities
- The easy.tools team — for payment handling and assistance in integrating our task system
- Alice — for brainstorming and helping to solve problems with examples that seemed unsolvable
- and above all — Katarzyna Gospodarczyk and Grzegorz Rog — for their presence.

See you,
Adam